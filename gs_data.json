{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "I_V0zBMAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Helin Wang", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=I_V0zBMAAAAJ&citpid=2", "affiliation": "Johns Hopkins University", "interests": ["Audio Processing", "Speech Processing", "Machine Learning"], "email_domain": "@jh.edu", "homepage": "https://wanghelin1997.github.io/helinwang/", "citedby": 906, "publications": {"I_V0zBMAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diffsound: Discrete diffusion model for text-to-sound generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:9ZlFYXVOiuMC", "num_citations": 304, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11532348218884559491", "cites_id": ["11532348218884559491"]}, "I_V0zBMAAAAJ:hFOr9nPyWt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Benchmarking large language models on cmexam-a comprehensive chinese medical exam dataset", "pub_year": "2024"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:hFOr9nPyWt4C", "num_citations": 72, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17548214150592475658", "cites_id": ["17548214150592475658"]}, "I_V0zBMAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Contrastive self-supervised learning for text-independent speaker verification", "pub_year": "2021"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:LkGwnXOMwfcC", "num_citations": 62, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17156048143861762099", "cites_id": ["17156048143861762099"]}, "I_V0zBMAAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Masked spectrogram prediction for self-supervised audio pre-training", "pub_year": "2022"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:Wp0gIr-vW9MC", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12220816877591891166", "cites_id": ["12220816877591891166"]}, "I_V0zBMAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification", "pub_year": "2021"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:hqOjcs7Dif8C", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13494838176994153973", "cites_id": ["13494838176994153973"]}, "I_V0zBMAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Environmental sound classification with parallel temporal-spectral attention", "pub_year": "2020"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:IjCSPb-OGe4C", "num_citations": 59, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11645570926672524150,15383971471115975154", "cites_id": ["11645570926672524150", "15383971471115975154"]}, "I_V0zBMAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Improving the Performance of Automated Audio Captioning via Integrating the Acoustic and Textual Information", "pub_year": "2021"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:8k81kl-MbHgC", "num_citations": 35, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16961035589767716396", "cites_id": ["16961035589767716396"]}, "I_V0zBMAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Mutual learning framework for Few-shot Sound Event Detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:kNdYIx-mwKoC", "num_citations": 30, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3542028934943863291", "cites_id": ["3542028934943863291"]}, "I_V0zBMAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Acoustic Scene Classification with Spectrogram Processing Strategies", "pub_year": "2020"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:u5HHmVD_uO8C", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12874138599546960701,2296837634260626495", "cites_id": ["12874138599546960701", "2296837634260626495"]}, "I_V0zBMAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-Oriented Multimodal Machine Comprehension via Dynamic Inter-and Intra-modality Attention", "pub_year": "2021"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:zYLM7Y9cAGgC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3783147909196267007,16310177830762747315", "cites_id": ["3783147909196267007", "16310177830762747315"]}, "I_V0zBMAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NoreSpeech: Knowledge Distillation based Conditional Diffusion Model for Noise-robust Expressive TTS", "pub_year": "2022"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:dhFuZR0502QC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4594110725415956343", "cites_id": ["4594110725415956343"]}, "I_V0zBMAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DuTa-VC: A Duration-aware Typical-to-atypical Voice Conversion Approach with Diffusion Probabilistic Model", "pub_year": "2023"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:IWHjjKOFINEC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2818432599610703664", "cites_id": ["2818432599610703664"]}, "I_V0zBMAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "What affects the performance of convolutional neural networks for audio event classification", "pub_year": "2019"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:u-x6o8ySG0sC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6378841521871954809", "cites_id": ["6378841521871954809"]}, "I_V0zBMAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Few-shot Bioacoustic Event Detection: A Good Transductive Inference is All You Need", "pub_year": "2021"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:5nxA0vEk-isC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10766181470734928498", "cites_id": ["10766181470734928498"]}, "I_V0zBMAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Modeling label dependencies for audio tagging with graph convolutional network", "pub_year": "2020"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:qjMakFHDy7sC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13344530700897385368", "cites_id": ["13344530700897385368"]}, "I_V0zBMAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Automated Audio Captioning with Temporal Attention", "pub_year": "2020"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:YsMSGLbcyi4C", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14117997299528154231,15787324495009169075", "cites_id": ["14117997299528154231", "15787324495009169075"]}, "I_V0zBMAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TeCANet: Temporal-Contextual Attention Network for Environment-Aware Speech Dereverberation", "pub_year": "2021"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:0EnyYjriUFMC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1597093254838511814", "cites_id": ["1597093254838511814"]}, "I_V0zBMAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Improving Target Sound Extraction with Timestamp Information", "pub_year": "2022"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:4DMP91E08xMC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18011628922097969461", "cites_id": ["18011628922097969461"]}, "I_V0zBMAAAAJ:ULOm3_A8WrAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Detect what you want: Target sound detection", "pub_year": "2021"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:ULOm3_A8WrAC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12790740009718269092", "cites_id": ["12790740009718269092"]}, "I_V0zBMAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A global-local attention framework for weakly labelled audio tagging", "pub_year": "2021"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:roLk4NBRz8UC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4244844470928610044", "cites_id": ["4244844470928610044"]}, "I_V0zBMAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback", "pub_year": "2024"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:_Qo2XoVZTnwC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10944991645369556382", "cites_id": ["10944991645369556382"]}, "I_V0zBMAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Featurecut: An adaptive data augmentation for automated audio captioning", "pub_year": "2022"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:ZeXyd9-uunAC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8433711955211851618", "cites_id": ["8433711955211851618"]}, "I_V0zBMAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unsupervised Multi-Target Domain Adaptation for Acoustic Scene Classification", "pub_year": "2021"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:Se3iqnhoufwC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4025971662494929682", "cites_id": ["4025971662494929682"]}, "I_V0zBMAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DPM-TSE: A Diffusion Probabilistic Model for Target Sound Extraction", "pub_year": "2024"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:RHpTSmoSYBkC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4897132069323951828", "cites_id": ["4897132069323951828"]}, "I_V0zBMAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Calibrate and Refine! A Novel and Agile Framework for ASR-error Robust Intent Detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:mVmsd5A6BfQC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8613791617721043716", "cites_id": ["8613791617721043716"]}, "I_V0zBMAAAAJ:TFP_iSt0sucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ezaudio: Enhancing text-to-audio generation with efficient diffusion transformer", "pub_year": "2024"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:TFP_iSt0sucC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7219863755895121096", "cites_id": ["7219863755895121096"]}, "I_V0zBMAAAAJ:r0BpntZqJG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dreamvoice: Text-guided voice conversion", "pub_year": "2024"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:r0BpntZqJG4C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11613319318437069037", "cites_id": ["11613319318437069037"]}, "I_V0zBMAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Improving fairness for spoken language understanding in atypical speech with Text-to-Speech", "pub_year": "2023"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:e5wmG9Sq2KIC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1016309849082610147", "cites_id": ["1016309849082610147"]}, "I_V0zBMAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RaDur: A Reference-aware and Duration-robust Network for Target Sound Detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:qxL8FJ1GzNcC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13929346343442443363", "cites_id": ["13929346343442443363"]}, "I_V0zBMAAAAJ:j3f4tGmQtD8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Noise-robust Speech Separation with Fast Generative Correction", "pub_year": "2024"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:j3f4tGmQtD8C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17117144961416393322", "cites_id": ["17117144961416393322"]}, "I_V0zBMAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Finding Spoken Identifications: Using GPT-4 Annotation for an Efficient and Fast Dataset Creation Pipeline", "pub_year": "2024"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:4JMBOYKVnBMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6051689050809775387", "cites_id": ["6051689050809775387"]}, "I_V0zBMAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Two-student Learning Framework for Mixed Supervised Target Sound Detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:aqlVkmm33-oC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15949998817452987709", "cites_id": ["15949998817452987709"]}, "I_V0zBMAAAAJ:bEWYMUwI8FkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SoloAudio: Target Sound Extraction with Language-oriented Audio Diffusion Transformer", "pub_year": "2024"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:bEWYMUwI8FkC", "num_citations": 0}, "I_V0zBMAAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SSR-Speech: Towards Stable, Safe and Robust Zero-shot Text-based Speech Editing and Synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "I_V0zBMAAAAJ:iH-uZ7U-co4C", "num_citations": 0}}, "citedby5y": 904, "hindex": 14, "hindex5y": 14, "i10index": 17, "i10index5y": 17, "cites_per_year": {"2020": 7, "2021": 66, "2022": 133, "2023": 229, "2024": 435, "2025": 29}, "updated": "2025-01-31 08:25:14.764608"}